{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7309c8d6-9396-4376-8e5e-a894dd5a6191",
   "metadata": {},
   "source": [
    "## 原始分类代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7e8de4-cb29-4552-8f4d-51f14cb6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0aed47d-7543-420f-a913-c129dfa293c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 16\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "\n",
    "nb_training_samples = 285\n",
    "nb_validation_samples = 72# Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3cc7144-5726-4a34-92eb-8e361fd9264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 285 images belonging to 3 classes.\n",
      "Found 72 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# training generator configuration\n",
    "training_data_dir = './melspectrograms/training'\n",
    "\n",
    "training_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    training_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# validation generator configuration\n",
    "validation_data_dir ='./melspectrograms/testing/'\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c782444-dea9-47e4-8fc1-a1a45e88b86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print('Model loaded.')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d4aafcd-f64c-4450-9305-317df2b4aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,423,555\n",
      "Trainable params: 6,423,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='softmax'))\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf4123c2-2fe8-443b-8591-979651cd0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 3)                 6423555   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,138,243\n",
      "Trainable params: 13,502,979\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# top_model.load_weights('bootlneck_fc_model.h5')\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e27b32a8-c9be-4880-90f7-35cd6a7c1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_to_freeze = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "009cc9a4-4ce2-4bc2-a9d5-96d7eb9a443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "\n",
    "for layer in model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# use nesterov accelrated gradient descent ??\n",
    "# optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer=optimizers.SGD(learning_rate=1e-5, momentum=0.9), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy', top_5_accuracy])\n",
    "\n",
    "# parallel_model.compile(optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9), \n",
    "#                       loss='categorical_crossentropy', \n",
    "#                       metrics=['accuracy', top_5_accuracy])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"vgg16_model_{}_frozen_layers.json\".format(num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1de84b3-e966-428a-b4a3-afa683005bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.8489 - accuracy: 0.6316 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 2s 83ms/step - loss: 0.8489 - accuracy: 0.6316 - top_5_accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 2/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.7719 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.7045 - accuracy: 0.7719 - top_5_accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 3/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.8667 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.5467 - accuracy: 0.8667 - top_5_accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 4/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8842 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.5126 - accuracy: 0.8842 - top_5_accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 5/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.9684 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.4114 - accuracy: 0.9684 - top_5_accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 6/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.9719 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 0.3941 - accuracy: 0.9719 - top_5_accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 7/16\n",
      "17/17 [===========================>..] - ETA: 0s - loss: 0.3452 - accuracy: 0.9779 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 0.3460 - accuracy: 0.9789 - top_5_accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 8/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.9895 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.3058 - accuracy: 0.9895 - top_5_accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 9/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.9930 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 0.2830 - accuracy: 0.9930 - top_5_accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 10/16\n",
      "17/17 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 1.0000 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.2347 - accuracy: 1.0000 - top_5_accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 11/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9965 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.2226 - accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 12/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9965 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 0.1969 - accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 13/16\n",
      "17/17 [===========================>..] - ETA: 0s - loss: 0.2011 - accuracy: 1.0000 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 0.2029 - accuracy: 1.0000 - top_5_accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 14/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 1.0000 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 0.2003 - accuracy: 1.0000 - top_5_accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 15/16\n",
      "17/17 [===========================>..] - ETA: 0s - loss: 0.1634 - accuracy: 1.0000 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.1613 - accuracy: 1.0000 - top_5_accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n",
      "Epoch 16/16\n",
      "18/17 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9965 - top_5_accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 0.1506 - accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 1.0000 - val_top_5_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7de224e80>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from time import time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/layers_frozen_{}\".format(num_layers_to_freeze))\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"esc50_vgg16_stft_weights_train_last_2_base_layers.best.hdf5\"\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard]\n",
    "\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     steps_per_epoch=nb_training_samples/batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,\n",
    "#     callbacks=callbacks_list)\n",
    "\n",
    "model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)\n",
    "# parallel_model.fit_generator(\n",
    "#     training_generator,\n",
    "#     samples_per_epoch=nb_training_samples,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples/batch_size,)\n",
    "#     nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db159097-41b9-4d0e-b1a2-6dcb886b782e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
